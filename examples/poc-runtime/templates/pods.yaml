{{- $root := . -}}
{{- $replicaCount := .Values.replicaCount -}}
{{- range $i := until (int $replicaCount) }}
{{- $nodeIndex := add $i 1 }}
---
apiVersion: v1
kind: Pod
metadata:
  name: {{ $root.Release.Name }}-{{ $nodeIndex }}
  labels:
    name: {{ $root.Release.Name }}-{{ $nodeIndex }}
    app.kubernetes.io/instance: {{ $root.Release.Name }}
  annotations:
    networking.gke.io/default-interface: 'eth0'
    networking.gke.io/interfaces: |
      [
        {"interfaceName":"eth0","network":"default"},
        {"interfaceName":"eth2","network":"rdma-0"},
        {"interfaceName":"eth3","network":"rdma-1"},
        {"interfaceName":"eth4","network":"rdma-2"},
        {"interfaceName":"eth5","network":"rdma-3"},
        {"interfaceName":"eth6","network":"rdma-4"},
        {"interfaceName":"eth7","network":"rdma-5"},
        {"interfaceName":"eth8","network":"rdma-6"},
        {"interfaceName":"eth9","network":"rdma-7"}
      ]
    kueue.x-k8s.io/podset-preferred-topology: "kubernetes.io/hostname"
    gke-gcsfuse/volumes: "true"
    gke-gcsfuse/cpu-limit: "0"
    gke-gcsfuse/memory-limit: "0"
    gke-gcsfuse/ephemeral-storage-limit: "0"
spec:
  hostNetwork: false
  hostPID: false
  serviceAccount: workload-identity-k8s-sa
  volumes:
    - name: local-ssd
      hostPath:
        path: /mnt/stateful_partition/kube-ephemeral-ssd
    - name: library-dir-host
      hostPath:
        path: /home/kubernetes/bin/nvidia
    - name: gib
      hostPath:
        path: /home/kubernetes/bin/gib
    - name: shared-memory
      emptyDir:
        medium: "Memory"
        sizeLimit: "250Gi"
  {{ if $root.Values.volumes.persistentVolumeClaims.checkpoint.claimName }}
    - name: checkpoint-volume
      persistentVolumeClaim:
        claimName: {{ $root.Values.volumes.persistentVolumeClaims.checkpoint.claimName }}
  {{ end }}
  {{ if $root.Values.volumes.persistentVolumeClaims.training.claimName }}
    - name: training-volume
      persistentVolumeClaim:
        claimName: {{ $root.Values.volumes.persistentVolumeClaims.training.claimName }}
  {{ end }}
  {{ if $root.Values.volumes.persistentVolumeClaims.nfs.claimName }}
    - name: nfs-volume
      persistentVolumeClaim:
        claimName: {{ $root.Values.volumes.persistentVolumeClaims.nfs.claimName }}
  {{ end }}
  containers:
    - image: "{{ $root.Values.images.container.repository }}:{{ $root.Values.images.container.tag }}"
      name: poc-runtime
      imagePullPolicy: {{ $root.Values.images.container.pullPolicy }}
      securityContext:
        privileged: true
      resources:
      {{ if $root.Values.resources.requests.cpu }}
        requests:
          cpu: {{ $root.Values.resources.requests.cpu }}
      {{ end }}
        limits:
          nvidia.com/gpu: {{ index $root.Values.resources.limits "nvidia.com/gpu" }}
      volumeMounts:
        - name: local-ssd
          mountPath: /scratch-data
        - name: library-dir-host
          mountPath: /usr/local/nvidia
        - name: gib
          mountPath: /usr/local/gib
        - name: shared-memory
          mountPath: /dev/shm
      {{ if $root.Values.volumes.persistentVolumeClaims.checkpoint.claimName }}
        - name: checkpoint-volume
          mountPath: /checkpoint_data
      {{ end }}
      {{ if $root.Values.volumes.persistentVolumeClaims.training.claimName }}
        - name: training-volume
          mountPath: /training_data
      {{ end }}
      {{ if $root.Values.volumes.persistentVolumeClaims.nfs.claimName }}
        - name: nfs-volume
          mountPath: /cfs
      {{ end }}
      env:
        - name: LD_LIBRARY_PATH
          value: /usr/local/nvidia/lib64
        - name: N_NODES
          value: "{{ $root.Values.replicaCount }}"
      command: ["/bin/bash", "-c"]
      args:
        - |
          cp -R /dev/shm/scripts /
          cp -R /dev/shm/diagnostic /
          cp -R /dev/shm/third_party /

          export N_NODES=${N_NODES}

          # Load all the cuda libs
          /sbin/ldconfig

          # Install ping
          apt update -y
          apt install -y iputils-ping openssh-server iproute2 pciutils

          # Install gcloud sdk
          echo "deb [signed-by=/usr/share/keyrings/cloud.google.gpg] https://packages.cloud.google.com/apt cloud-sdk main" | \
            tee -a /etc/apt/sources.list.d/google-cloud-sdk.list && \
            curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | \
            gpg --dearmor -o /usr/share/keyrings/cloud.google.gpg && \
            apt-get update -y && \
            apt-get install google-cloud-cli -y

          # Enable persistence
          for i in $(seq 0 7)
          do
            nvidia-smi -i $i -pm ENABLED
          done

          # Setup ssh
          cp /training_data/id_rsa* /training_data/authorized_keys /root/.ssh/
          chmod 400 /root/.ssh/id_rsa
          sed -i 's/^#PermitRootLogin prohibit-password/PermitRootLogin prohibit-password/' /etc/ssh/sshd_config
          echo "Port 222" | tee -a /etc/ssh/sshd_config > /dev/null
          service ssh restart

          # Setup variables
          echo "unset NCCL_NVLS_ENABLE TORCH_NCCL_USE_COMM_NONBLOCKING" | tee -a /root/.bashrc > /dev/null
          echo "export LD_LIBRARY_PATH=/usr/local/gib/lib64:${LD_LIBRARY_PATH}" | tee -a /root/.bashrc > /dev/null
          echo "source /usr/local/gib/scripts/set_nccl_env.sh" | tee -a /root/.bashrc > /dev/null

          #
          python -m pip install --upgrade pip
          pip install sentencepiece

          # Get helper variables to form all hostnames
          export POSTFIX=$(hostname | cut -d . -f 2-)
          export WORKERS_BASENAME=$(hostname | cut -d . -f 1 | rev | cut -d - -f 2- | rev )

          # For every worker, wait till online and add to hostfile
          for i in `seq 1 $(($N_NODES))`; do
            OTHER=${WORKERS_BASENAME}-${i}
            until ssh -p 222 -o StrictHostKeyChecking=no $OTHER hostname; do
              echo Waiting for ${OTHER}...
              sleep 10
            done
            echo ${OTHER} port=222 slots=8 | tee -a /tmp/hostfile;
          done

          sleep infinity
  initContainers:
    - name: nccl-plugin-installer
      image: "{{ $root.Values.images.initContainer.repository }}:{{ $root.Values.images.initContainer.tag }}"
      imagePullPolicy: {{ $root.Values.images.initContainer.pullPolicy }}
      args:
      - |
        set -ex
        /scripts/container_entry.sh install --install-nccl
        cp -R /var/lib/gib/lib64/. /target/usr/local/gib/lib64
        cp -R /var/lib/gib/. /target/usr/local/gib
        cp -R /scripts /target/dev/shm
        cp -R /diagnostic /target/dev/shm
        cp -R /third_party /target/dev/shm
      command:
      - /bin/sh
      - -c
      volumeMounts:
      - mountPath: /target/usr/local/gib
        name: gib
      - mountPath: /target/dev/shm
        name: shared-memory
{{- end }}
